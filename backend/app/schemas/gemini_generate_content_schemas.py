from __future__ import annotations

from pydantic import BaseModel, ConfigDict, Field, field_validator, model_validator

from .gemini_enums import (
    Behavior,
    BlockReason,
    DynamicRetrievalMode,
    FinishReason,
    FunctionCallingConfigMode,
    HarmBlockThreshold,
    HarmCategory,
    HarmProbability,
    Language,
    MediaResolution,
    Modality,
    Outcome,
    Role,
    Scheduling,
    SchemaFormat,
    Type,
    UrlRetrievalStatus,
)


class Blob(BaseModel):
    mime_type: str = Field(..., alias="mimeType", description="The IANA standard MIME type of the source data.")
    data: str = Field(..., description="Raw bytes for media formats. A base64-encoded string.")

    model_config = ConfigDict(populate_by_name=True)


class FileData(BaseModel):
    mime_type: str | None = Field(None, alias="mimeType", description="Optional. The IANA standard MIME type of the source data.")
    file_uri: str = Field(..., alias="fileUri", description="Required. URI.")

    model_config = ConfigDict(populate_by_name=True)


class FunctionCall(BaseModel):
    id: str | None = Field(None, description="Optional. The unique id of the function call.")
    name: str = Field(..., description="Required. The name of the function to call.")
    args: dict | None = Field({}, description="Optional. The function parameters and values in JSON object format.")


class FunctionResponse(BaseModel):
    id: str | None = Field(None, description="Optional. The id of the function call this response is for.")
    name: str = Field(..., description="Required. The name of the function to call.")
    response: dict = Field(..., description="Required. The function response in JSON object format.")
    will_continue: bool | None = Field(None, alias="willContinue", description="Optional. Signals that function call continues.")
    scheduling: Scheduling | None = Field(None, description="Optional. Specifies how the response should be scheduled.")

    model_config = ConfigDict(populate_by_name=True)


class VideoMetadata(BaseModel):
    start_offset: str | None = Field(None, alias="startOffset", description="The start offset of the video.")
    end_offset: str | None = Field(None, alias="endOffset", description="The end offset of the video.")
    fps: float | None = Field(None, description="Optional. The frame rate of the video sent to the model.")

    model_config = ConfigDict(populate_by_name=True)


class ExecutableCode(BaseModel):
    language: Language = Field(..., description="Required. The programming language of the code.")
    code: str = Field(..., description="Required. The code to be executed.")


class CodeExecutionResult(BaseModel):
    outcome: Outcome = Field(..., description="Required. The outcome of the code execution.")
    output: str | None = Field(None, description="Optional. The output of the code execution.")

    model_config = ConfigDict(populate_by_name=True)


class Part(BaseModel):
    thought: bool | None = Field(None, description="Optional. Indicates if the part is thought from the model.")
    thought_signature: str | None = Field(
        None,
        description="Optional. An opaque signature for the thought so it can be reused in subsequent requests.",
        alias="thoughtSignature",
    )
    # data
    text: str | None = Field(None, description="Inline text.")
    inline_data: Blob | None = Field(None, description="Inline media bytes.", alias="inlineData")
    function_call: FunctionCall | None = Field(None, description="A predicted FunctionCall returned from the model.", alias="functionCall")
    function_response: FunctionResponse | None = Field(None, description="The result output of a FunctionCall.", alias="functionResponse")
    file_data: FileData | None = Field(None, description="URI based data.", alias="fileData")
    executable_code: ExecutableCode | None = Field(
        None, description="Code generated by the model that is meant to be executed.", alias="executableCode"
    )
    code_execution_result: CodeExecutionResult | None = Field(
        None, description="Result of executing the ExecutableCode.", alias="codeExecutionResult"
    )
    # metadata
    video_metadata: VideoMetadata | None = Field(None, description="Optional. Video metadata.", alias="videoMetadata")

    @model_validator(mode="after")
    def check_exactly_one_data_field(self) -> "Part":
        data_fields = [
            "text",
            "inline_data",
            "function_call",
            "function_response",
            "file_data",
            "executable_code",
            "code_execution_result",
        ]
        set_fields_count = sum(1 for field in data_fields if getattr(self, field) is not None)
        if set_fields_count != 1:
            raise ValueError(f"Exactly one of the fields {data_fields} must be set.")
        return self

    model_config = ConfigDict(populate_by_name=True)


class Content(BaseModel):
    parts: list[Part] = Field(..., description="Ordered Parts that constitute a single message.")
    role: Role | None = Field(None, description="Optional. The producer of the content. Must be either 'user' or 'model'.")


class SafetySetting(BaseModel):
    category: HarmCategory = Field(..., description="Required. The category for this setting.")
    threshold: HarmBlockThreshold = Field(..., description="Required. Controls the probability threshold at which harm is blocked.")


class PrebuiltVoiceConfig(BaseModel):
    voice_name: str = Field(..., alias="voiceName", description="The name of the preset voice to use.")

    model_config = ConfigDict(populate_by_name=True)


class VoiceConfig(BaseModel):
    prebuilt_voice_config: PrebuiltVoiceConfig | None = Field(
        None, alias="prebuiltVoiceConfig", description="The configuration for the prebuilt voice to use."
    )

    model_config = ConfigDict(populate_by_name=True)


class SpeakerVoiceConfig(BaseModel):
    speaker: str = Field(..., description="Required. The name of the speaker to use. Should be the same as in the prompt.")
    voice_config: VoiceConfig = Field(..., alias="voiceConfig", description="Required. The configuration for the voice to use.")

    model_config = ConfigDict(populate_by_name=True)


class MultiSpeakerVoiceConfig(BaseModel):
    speaker_voice_configs: list[SpeakerVoiceConfig] = Field(
        ..., alias="speakerVoiceConfigs", description="Required. All the enabled speaker voices."
    )

    model_config = ConfigDict(populate_by_name=True)


class SpeechConfig(BaseModel):
    voice_config: VoiceConfig | None = Field(None, alias="voiceConfig", description="The configuration in case of single-voice output.")
    multi_speaker_voice_config: MultiSpeakerVoiceConfig | None = Field(
        None, alias="multiSpeakerVoiceConfig", description="Optional. The configuration for the multi-speaker setup."
    )
    language_code: str | None = Field(None, alias="languageCode", description="Optional. Language code for speech synthesis.")

    model_config = ConfigDict(populate_by_name=True)

    @model_validator(mode="after")
    def check_exclusive_fields(self) -> SpeechConfig:
        if self.voice_config is not None and self.multi_speaker_voice_config is not None:
            raise ValueError("voice_config and multi_speaker_voice_config are mutually exclusive.")
        return self


class ThinkingConfig(BaseModel):
    include_thoughts: bool | None = Field(
        None, alias="includeThoughts", description="Indicates whether to include thoughts in the response."
    )
    thinking_budget: int | None = Field(
        None, alias="thinkingBudget", description="The number of thoughts tokens that the model should generate."
    )

    model_config = ConfigDict(populate_by_name=True)


class GenerationConfig(BaseModel):
    stop_sequences: list[str] | None = Field(
        None, alias="stopSequences", description="Optional. The set of character sequences (up to 5) that will stop output generation."
    )
    response_mime_type: str | None = Field(
        None, alias="responseMimeType", description="Optional. MIME type of the generated candidate text."
    )
    response_schema: Schema | None = Field(None, alias="responseSchema", description="Output schema of the generated candidate text.")
    response_json_schema: dict | None = Field(
        None, alias="responseJsonSchema", description="Optional. Output schema of the generated response in JSON Schema format."
    )
    response_modalities: list[Modality] | None = Field(
        None, alias="responseModalities", description="Optional. The requested modalities of the response."
    )
    candidate_count: int | None = Field(None, alias="candidateCount", description="Number of generated responses to return.")
    max_output_tokens: int | None = Field(
        None, alias="maxOutputTokens", description="The maximum number of tokens to include in a response candidate."
    )
    temperature: float | None = Field(None, ge=0.0, le=2.0, description="Controls the randomness of the output.")
    top_p: float | None = Field(None, alias="topP", description="The maximum cumulative probability of tokens to consider when sampling.")
    top_k: int | None = Field(None, alias="topK", description="The maximum number of tokens to consider when sampling.")
    seed: int | None = Field(None, description="Optional. Seed used in decoding.")
    presence_penalty: float | None = Field(
        None, alias="presencePenalty", description="Optional. Presence penalty applied to the next token's logprobs."
    )
    frequency_penalty: float | None = Field(
        None, alias="frequencyPenalty", description="Optional. Frequency penalty applied to the next token's logprobs."
    )
    response_logprobs: bool | None = Field(
        None, alias="responseLogprobs", description="Optional. If true, export the logprobs results in response."
    )
    logprobs: int | None = Field(None, description="Optional. This sets the number of top logprobs to return at each decoding step.")
    enable_enhanced_civic_answers: bool | None = Field(
        None, alias="enableEnhancedCivicAnswers", description="Optional. Enables enhanced civic answers."
    )
    speech_config: SpeechConfig | None = Field(None, alias="speechConfig", description="Optional. The speech generation config.")
    thinking_config: ThinkingConfig | None = Field(None, alias="thinkingConfig", description="Optional. Config for thinking features.")
    media_resolution: MediaResolution | None = Field(
        None, alias="mediaResolution", description="Optional. If specified, the media resolution specified will be used."
    )

    model_config = ConfigDict(populate_by_name=True)


class Schema(BaseModel):
    type: Type = Field(..., description="Required. Data type.")
    format: SchemaFormat | None = Field(None, description="Optional. The format of the data.")
    title: str | None = Field(None, description="Optional. The title of the schema.")
    description: str | None = Field(None, description="Optional. A brief description of the parameter.")
    nullable: bool | None = Field(None, description="Optional. Indicates if the value may be null.")
    enum: list[str] | None = Field(None, description="Optional. Possible values of the element of Type.STRING with enum format.")
    max_items: str | None = Field(None, alias="maxItems", description="Optional. Maximum number of the elements for Type.ARRAY.")
    min_items: str | None = Field(None, alias="minItems", description="Optional. Minimum number of the elements for Type.ARRAY.")
    properties: dict[str, Schema] | None = Field(None, description="Optional. Properties of Type.OBJECT.")
    required: list[str] | None = Field(None, description="Optional. Required properties of Type.OBJECT.")
    min_properties: str | None = Field(
        None, alias="minProperties", description="Optional. Minimum number of the properties for Type.OBJECT."
    )
    max_properties: str | None = Field(
        None, alias="maxProperties", description="Optional. Maximum number of the properties for Type.OBJECT."
    )
    min_length: str | None = Field(
        None, alias="minLength", description="Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING"
    )
    max_length: str | None = Field(None, alias="maxLength", description="Optional. Maximum length of the Type.STRING")
    pattern: str | None = Field(None, description="Optional. Pattern of the Type.STRING to restrict a string to a regular expression.")
    example: dict | None = Field(None, description="Optional. Example of the object.")
    any_of: list[Schema] | None = Field(
        None, alias="anyOf", description="Optional. The value should be validated against any (one or more) of the subschemas in the list."
    )
    property_ordering: list[str] | None = Field(None, alias="propertyOrdering", description="Optional. The order of the properties.")
    default: dict | None = Field(None, description="Optional. Default value of the field.")
    items: Schema | None = Field(None, description="Optional. Schema of the elements of Type.ARRAY.")
    minimum: float | None = Field(
        None, description="Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER"
    )
    maximum: float | None = Field(None, description="Optional. Maximum value of the Type.INTEGER and Type.NUMBER")

    @field_validator("min_items", "max_items", "min_properties", "max_properties", "min_length", "max_length")
    def check_integer_format(cls, v: str | None) -> str | None:
        if v is None:
            return v
        try:
            int(v)
        except ValueError:
            raise ValueError(f"'{v}' is not a valid integer string")
        return v

    model_config = ConfigDict(populate_by_name=True)


class FunctionDeclaration(BaseModel):
    name: str = Field(..., description="Required. The name of the function.")
    description: str = Field(..., description="Required. A brief description of the function.")
    behavior: Behavior | None = Field(None, description="Optional. Specifies the function Behavior.")
    parameters: Schema | None = Field(None, description="Optional. Describes the parameters to this function.")
    parameters_json_schema: dict | None = Field(
        None, alias="parametersJsonSchema", description="Optional. Describes the parameters to the function in JSON Schema format."
    )
    response: Schema | None = Field(None, description="Optional. Describes the output from this function in JSON Schema format.")
    response_json_schema: dict | None = Field(
        None, alias="responseJsonSchema", description="Optional. Describes the output from this function in JSON Schema format."
    )

    @model_validator(mode="after")
    def check_parameters_exclusive(self) -> FunctionDeclaration:
        if self.parameters is not None and self.parameters_json_schema is not None:
            raise ValueError("parameters and parameters_json_schema are mutually exclusive.")
        if self.response is not None and self.response_json_schema is not None:
            raise ValueError("response and response_json_schema are mutually exclusive.")
        return self

    model_config = ConfigDict(populate_by_name=True)


class DynamicRetrievalConfig(BaseModel):
    mode: DynamicRetrievalMode = Field(..., description="The mode of the predictor to be used in dynamic retrieval.")
    dynamic_threshold: float | None = Field(
        None,
        alias="dynamicThreshold",
        description="The threshold to be used in dynamic retrieval. If not set, a system default value is used.",
    )

    model_config = ConfigDict(populate_by_name=True)


class GoogleSearchRetrieval(BaseModel):
    dynamic_retrieval_config: DynamicRetrievalConfig = Field(
        ..., alias="dynamicRetrievalConfig", description="Specifies the dynamic retrieval configuration for the given source."
    )

    model_config = ConfigDict(populate_by_name=True)


class Interval(BaseModel):
    start_time: str | None = Field(
        None,
        alias="startTime",
        description=(
            "Optional. Inclusive start of the interval. If specified, a Timestamp matching this interval will have to be the same or after the start. "
            'Uses RFC 3339, where generated output will always be Z-normalized and uses 0, 3, 6 or 9 fractional digits. Offsets other than "Z" are also accepted. '
            'Examples: "2014-10-02T15:01:23Z", "2014-10-02T15:01:23.045123456Z" or "2014-10-02T15:01:23+05:30".'
        ),
    )
    end_time: str | None = Field(
        None,
        alias="endTime",
        description=(
            "Optional. Exclusive end of the interval. If specified, a Timestamp matching this interval will have to be before the end. "
            'Uses RFC 3339, where generated output will always be Z-normalized and uses 0, 3, 6 or 9 fractional digits. Offsets other than "Z" are also accepted. '
            'Examples: "2014-10-02T15:01:23Z", "2014-10-02T15:01:23.045123456Z" or "2014-10-02T15:01:23+05:30".'
        ),
    )

    model_config = ConfigDict(populate_by_name=True)


class GoogleSearch(BaseModel):
    time_range_filter: Interval | None = Field(
        None,
        alias="timeRangeFilter",
        description="Optional. Filter search results to a specific time range. If customers set a start time, they must set an end time (and vice versa).",
    )

    model_config = ConfigDict(populate_by_name=True)


class Tool(BaseModel):
    function_declarations: list[FunctionDeclaration] | None = Field(
        None,
        alias="functionDeclarations",
        description="A list of FunctionDeclarations available to the model that can be used for function calling.",
    )
    google_search_retrieval: GoogleSearchRetrieval | None = Field(
        None, alias="googleSearchRetrieval", description="Retrieval tool that is powered by Google search."
    )
    code_execution: dict | None = Field(None, alias="codeExecution", description="Enables the model to execute code as part of generation.")
    google_search: GoogleSearch | None = Field(None, alias="googleSearch", description="GoogleSearch tool type.")
    url_context: dict | None = Field(None, alias="urlContext", description="Tool to support URL context retrieval.")

    model_config = ConfigDict(populate_by_name=True)


class FunctionCallingConfig(BaseModel):
    mode: FunctionCallingConfigMode | None = Field(
        None,
        description="Optional. Specifies the mode in which function calling should execute. If unspecified, the default value will be set to AUTO.",
    )
    allowed_function_names: list[str] | None = Field(
        None,
        alias="allowedFunctionNames",
        description="Optional. A set of function names that, when provided, limits the functions the model will call.",
    )

    model_config = ConfigDict(populate_by_name=True)


class ToolConfig(BaseModel):
    function_calling_config: FunctionCallingConfig | None = Field(
        None, alias="functionCallingConfig", description="Function calling config."
    )

    model_config = ConfigDict(populate_by_name=True)


class GenerateContentPayload(BaseModel):
    contents: list[Content] = Field(..., description="Required. The content of the current conversation with the model.")
    tools: list[Tool] | None = Field(None, description="Optional. A list of `Tools` the `Model` may use to generate the next response.")
    tool_config: ToolConfig | None = Field(
        None, alias="toolConfig", description="Optional. Tool configuration for any `Tool` specified in the request."
    )
    safety_settings: list[SafetySetting] | None = Field(
        None, alias="safetySettings", description="Optional. A list of unique `SafetySetting` instances for blocking unsafe content."
    )
    system_instruction: Content | None = Field(
        None, alias="systemInstruction", description="Optional. Developer set system instruction(s). Currently, text only."
    )
    generation_config: GenerationConfig | None = Field(
        None, alias="generationConfig", description="Optional. Configuration options for model generation and outputs."
    )
    cached_content: str | None = Field(
        None,
        alias="cachedContent",
        description="Optional. The name of the content cached to use as context to serve the prediction.",
    )

    model_config = ConfigDict(populate_by_name=True)


class CitationSource(BaseModel):
    start_index: int | None = Field(
        None,
        alias="startIndex",
        description="Optional. Start of segment of the response that is attributed to this source. Index indicates the start of the segment, measured in bytes.",
    )
    end_index: int | None = Field(None, alias="endIndex", description="Optional. End of the attributed segment, exclusive.")
    uri: str | None = Field(None, description="Optional. URI that is attributed as a source for a portion of the text.")
    license: str | None = Field(None, description="Optional. License for the GitHub project that is attributed as a source for segment.")


class CitationMetadata(BaseModel):
    citation_sources: list[CitationSource] = Field(
        default_factory=list, alias="citationSources", description="Citations to sources for a specific response."
    )


class GroundingPassageId(BaseModel):
    passage_id: str | None = Field(
        None, alias="passageId", description="Output only. ID of the passage matching the `GenerateAnswerRequest`'s `GroundingPassage.id`."
    )
    part_index: int | None = Field(
        None,
        alias="partIndex",
        description="Output only. Index of the part within the `GenerateAnswerRequest`'s `GroundingPassage.content`.",
    )

    model_config = ConfigDict(populate_by_name=True)


class SemanticRetrieverChunk(BaseModel):
    source: str = Field(
        ...,
        description="Output only. Name of the source matching the request's `SemanticRetrieverConfig.source`. Example: `corpora/123` or `corpora/123/documents/abc`",
    )
    chunk: str = Field(
        ..., description="Output only. Name of the `Chunk` containing the attributed text. Example: `corpora/123/documents/abc/chunks/xyz`"
    )


class AttributionSourceId(BaseModel):
    grounding_passage: GroundingPassageId | None = Field(None, alias="groundingPassage", description="Identifier for an inline passage.")
    semantic_retriever_chunk: SemanticRetrieverChunk | None = Field(
        None, alias="semanticRetrieverChunk", description="Identifier for a `Chunk` fetched via Semantic Retriever."
    )

    @model_validator(mode="after")
    def check_exactly_one_source_field(self) -> "AttributionSourceId":
        set_fields_count = sum(1 for field in ["grounding_passage", "semantic_retriever_chunk"] if getattr(self, field) is not None)
        if set_fields_count != 1:
            raise ValueError("Exactly one of grounding_passage or semantic_retriever_chunk must be set.")
        return self

    model_config = ConfigDict(populate_by_name=True)


class GroundingAttribution(BaseModel):
    source_id: AttributionSourceId = Field(
        ..., alias="sourceId", description="Output only. Identifier for the source contributing to this attribution."
    )
    content: Content = Field(..., description="Grounding source content that makes up this attribution.")


class Web(BaseModel):
    uri: str = Field(..., description="URI reference of the chunk.")
    title: str = Field(..., description="Title of the chunk.")


class GroundingChunk(BaseModel):
    web: Web = Field(..., description="Grounding chunk from the web.")


class Segment(BaseModel):
    part_index: int | None = Field(
        None, alias="partIndex", description="Output only. The index of a Part object within its parent Content object."
    )
    start_index: int | None = Field(
        None,
        alias="startIndex",
        description="Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.",
    )
    end_index: int | None = Field(
        None,
        alias="endIndex",
        description="Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.",
    )
    text: str | None = Field(None, description="Output only. The text corresponding to the segment from the response.")

    model_config = ConfigDict(populate_by_name=True)


class GroundingSupport(BaseModel):
    grounding_chunk_indices: list[int] = Field(
        ...,
        alias="groundingChunkIndices",
        description="A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.",
    )
    confidence_scores: list[float] = Field(
        ...,
        alias="confidenceScores",
        description="Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. This list must have the same size as the groundingChunkIndices.",
    )
    segment: Segment = Field(..., description="Segment of the content this support belongs to.")

    model_config = ConfigDict(populate_by_name=True)


class RetrievalMetadata(BaseModel):
    google_search_dynamic_retrieval_score: float | None = Field(
        None,
        alias="googleSearchDynamicRetrievalScore",
        description="Optional. Score indicating how likely information from google search could help answer the prompt. The score is in the range [0, 1], where 0 is the least likely and 1 is the most likely. This score is only populated when google search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger google search.",
    )


class SearchEntryPoint(BaseModel):
    rendered_content: str | None = Field(
        None, alias="renderedContent", description="Optional. Web content snippet that can be embedded in a web page or an app webview."
    )
    sdk_blob: str | None = Field(
        None,
        alias="sdkBlob",
        description="Optional. Base64 encoded JSON representing array of <search term, search url> tuple.A base64-encoded string.",
    )

    model_config = ConfigDict(populate_by_name=True)


class GroundingMetadata(BaseModel):
    grounding_chunks: list[GroundingChunk] | None = Field(
        None, alias="groundingChunks", description="List of supporting references retrieved from specified grounding source."
    )
    grounding_supports: list[GroundingSupport] | None = Field(None, alias="groundingSupports", description="List of grounding support.")
    web_search_queries: list[str] | None = Field(
        None, alias="webSearchQueries", description="Web search queries for the following-up web search."
    )
    search_entry_point: SearchEntryPoint | None = Field(
        None, alias="searchEntryPoint", description="Optional. Google search entry for the following-up web searches."
    )
    retrieval_metadata: RetrievalMetadata | None = Field(
        None, alias="retrievalMetadata", description="Metadata related to retrieval in the grounding flow."
    )

    model_config = ConfigDict(populate_by_name=True)


class LogprobsCandidate(BaseModel):
    token: str = Field(..., description="The candidate's token string value.")
    token_id: int = Field(..., alias="tokenId", description="The candidate's token id value.")
    log_probability: float = Field(..., alias="logProbability", description="The candidate's log probability.")

    model_config = ConfigDict(populate_by_name=True)


class TopCandidates(BaseModel):
    candidates: list[LogprobsCandidate] = Field(..., description="Sorted by log probability in descending order.")


class LogprobsResult(BaseModel):
    top_candidates: list[TopCandidates] = Field(..., alias="topCandidates", description="Length = total number of decoding steps.")
    chosen_candidates: list[LogprobsCandidate] = Field(
        ...,
        alias="chosenCandidates",
        description="Length = total number of decoding steps. The chosen candidates may or may not be in topCandidates.",
    )

    model_config = ConfigDict(populate_by_name=True)


class UrlMetadata(BaseModel):
    retrieved_url: str = Field(..., alias="retrievedUrl", description="Retrieved url by the tool.")
    url_retrieval_status: UrlRetrievalStatus = Field(..., alias="urlRetrievalStatus", description="Status of the url retrieval.")

    model_config = ConfigDict(populate_by_name=True)


class UrlContextMetadata(BaseModel):
    url_metadata: list[UrlMetadata] = Field(..., alias="urlMetadata", description="List of url context.")

    model_config = ConfigDict(populate_by_name=True)


class SafetyRating(BaseModel):
    category: HarmCategory = Field(..., description="Required. The category for this rating.")
    probability: HarmProbability = Field(..., description="Required. The probability of harm for this content.")
    blocked: bool | None = Field(None, description="Was this content blocked because of this rating?")


class Candidate(BaseModel):
    content: Content = Field(..., description="Output only. Generated content returned from the model.")
    finish_reason: FinishReason | None = Field(
        None,
        alias="finishReason",
        description="Optional. Output only. The reason why the model stopped generating tokens. If empty, the model has not stopped generating tokens.",
    )
    safety_ratings: list[SafetyRating] | None = Field(
        None,
        alias="safetyRatings",
        description="List of ratings for the safety of a response candidate. There is at most one rating per category.",
    )
    citation_metadata: CitationMetadata | None = Field(
        None,
        alias="citationMetadata",
        description="Output only. Citation information for model-generated candidate. This field may be populated with recitation information for any text included in the `content`. These are passages that are 'recited' from copyrighted material in the foundational LLM's training data.",
    )
    token_count: int | None = Field(None, alias="tokenCount", description="Output only. Token count for this candidate.")
    grounding_attributions: list[GroundingAttribution] | None = Field(
        None,
        alias="groundingAttributions",
        description="Output only. Attribution information for sources that contributed to a grounded answer. This field is populated for `GenerateAnswer` calls.",
    )
    grounding_metadata: GroundingMetadata | None = Field(
        None,
        alias="groundingMetadata",
        description="Output only. Grounding metadata for the candidate. This field is populated for `GenerateContent` calls.",
    )
    avg_logprobs: float | None = Field(
        None, alias="avgLogprobs", description="Output only. Average log probability score of the candidate."
    )
    logprobs_result: LogprobsResult | None = Field(
        None, alias="logprobsResult", description="Output only. Log-likelihood scores for the response tokens and top tokens"
    )
    url_context_metadata: UrlContextMetadata | None = Field(
        None, alias="urlContextMetadata", description="Output only. Metadata related to url context retrieval tool."
    )
    index: int | None = Field(None, description="Output only. Index of the candidate in the list of response candidates.")

    model_config = ConfigDict(populate_by_name=True)


class PromptFeedback(BaseModel):
    block_reason: BlockReason | None = Field(
        None,
        alias="blockReason",
        description="Optional. If set, the prompt was blocked and no candidates are returned. Rephrase the prompt.",
    )
    safety_ratings: list[SafetyRating] = Field(
        ..., description="Ratings for safety of the prompt. There is at most one rating per category."
    )

    model_config = ConfigDict(populate_by_name=True)


class ModalityTokenCount(BaseModel):
    modality: Modality = Field(..., description="The modality associated with this token count.")
    token_count: int = Field(..., alias="tokenCount", description="Number of tokens.")

    model_config = ConfigDict(populate_by_name=True)


class UsageMetadata(BaseModel):
    prompt_token_count: int | None = Field(None, alias="promptTokenCount", description="Number of tokens in the prompt.")
    cached_content_token_count: int | None = Field(
        None, alias="cachedContentTokenCount", description="Number of tokens in the cached part of the prompt (the cached content)."
    )
    candidates_token_count: int | None = Field(
        None, alias="candidatesTokenCount", description="Total number of tokens across all the generated response candidates."
    )
    tool_use_prompt_token_count: int | None = Field(
        None, alias="toolUsePromptTokenCount", description="Output only. Number of tokens present in tool-use prompt(s)."
    )
    thoughts_token_count: int | None = Field(
        None, alias="thoughtsTokenCount", description="Output only. Number of tokens of thoughts for thinking models."
    )
    total_token_count: int | None = Field(
        None, alias="totalTokenCount", description="Total token count for the generation request (prompt + response candidates)."
    )
    prompt_tokens_details: list[ModalityTokenCount] | None = Field(
        None, alias="promptTokensDetails", description="Output only. List of modalities that were processed in the request input."
    )
    cache_tokens_details: list[ModalityTokenCount] | None = Field(
        None, alias="cacheTokensDetails", description="Output only. List of modalities of the cached content in the request input."
    )
    candidates_tokens_details: list[ModalityTokenCount] | None = Field(
        None, alias="candidatesTokensDetails", description="Output only. List of modalities that were returned in the response."
    )
    tool_use_prompt_tokens_details: list[ModalityTokenCount] | None = Field(
        None,
        alias="toolUsePromptTokensDetails",
        description="Output only. List of modalities that were processed for tool-use request inputs.",
    )

    model_config = ConfigDict(populate_by_name=True)


class GenerateContentResponse(BaseModel):
    candidates: list[Candidate] = Field(..., description="Candidate responses from the model.")
    prompt_feedback: PromptFeedback | None = Field(
        None, alias="promptFeedback", description="Returns the prompt's feedback related to the content filters."
    )
    usage_metadata: UsageMetadata | None = Field(
        None, alias="usageMetadata", description="Output only. Metadata on the generation requests' token usage."
    )
    model_version: str | None = Field(
        None, alias="modelVersion", description="Output only. The model version used to generate the response."
    )
    response_id: str | None = Field(None, alias="responseId", description="Output only. responseId is used to identify each response.")

    model_config = ConfigDict(populate_by_name=True)
